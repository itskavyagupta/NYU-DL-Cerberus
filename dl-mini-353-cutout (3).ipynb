{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":73233,"databundleVersionId":8112053,"sourceType":"competition"}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Parameters that can be changed according to the environment, number of epochs, learning rate, etc.\n\n# To choose kaggle vs colab notebooks\nkaggle = 1 # 1 if kaggle, 0 if colab\nload_dataset_online = 0 # 0 if kaggle, as the Kaggle competition already had the dataset, 1 to download teh dataset\nuse_wandb = 0 # 1 to use wandb (Weights And Biases) and save our sweeps to wandb, 0 to not run wandb\nwandbapi = '' ## add wandb API key from wandb.com/authorize, otherwise wandb won't work\n\n# model config to pass to our main model\nblocks = [3,5,3]\nchannels = [64,128,256]\n\nearlystop = 0 # to use early stop for our training\n\n#number of epochs\nnumber_of_epochs = 200 # max epochs\nsave_freq = 15 # number of epochs after which we save our model\n\n#early stopping criterion\nearlystop_patience = 5\nearlystop_mindelta = 2\nearlystop_threshold = 88\n\n# to create csv\nfinal_test_create_csv=0\n\n# hyperparameters if not using wandb\nargs_weight_decay = 5e-4\nargs_lr = 0.01\nargs_optimizer = 'sgd' # options: sgd, sgdn, adadelta-clipping,\n\n# load model\nload_model = 0\nload_model_name = '100_checkpoint.tar' #can only be done on colab\n\n# other parameters\nour_batch_size = 128\nour_number_workers = 2\n\n# Maximum number of iterations for annealing\nt_max = 50","metadata":{"id":"f9feviImC5sG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing all the required libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\n\nimport pickle\n\nimport argparse\n\nfrom PIL import Image\n\nimport pprint\n\n# from utils import progress_bar\nfrom time import perf_counter\n\n# installing wandb\n!pip install wandb -Uq\nimport wandb\n\nimport os\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"CdKFRqDQCekk","outputId":"2e993186-6d0f-4f13-c1e3-e67cd112c8f1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating proper path names for kaggle \n\nif kaggle==1:\n  for dirname, _, filenames in os.walk('/kaggle/input'):\n      for filename in filenames:\n          print(os.path.join(dirname, filename))","metadata":{"id":"ODX4aHq7C0X0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ResNet model\nclass BasicBlock(nn.Module):\n   expansion = 1\n\n   def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(\n                in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n                                                   stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n                self.shortcut = nn.Sequential(\n                        nn.Conv2d(in_planes, self.expansion*planes,\n                                          kernel_size=1, stride=stride, bias=False),\n                        nn.BatchNorm2d(self.expansion*planes)\n                )\n\n   def forward(self, x):\n\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\nclass ResNet3(nn.Module):\n   def __init__(self, block, num_blocks, channels = [64, 128, 256], num_classes=10):\n        super(ResNet3, self).__init__()\n        self.in_planes = channels[0]\n\n        self.conv1 = nn.Conv2d(3, channels[0], kernel_size=3,\n                                                   stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(channels[0])\n        self.layer1 = self._make_layer(block, channels[0], num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, channels[1], num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, channels[2], num_blocks[2], stride=2)\n        # self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(channels[2]*block.expansion, num_classes)\n\n   def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n                layers.append(block(self.in_planes, planes, stride))\n                self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n   def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        # out = self.layer4(out)\n        out = F.avg_pool2d(out, 8) #changed from 4 to 8\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\nclass ResNet4(nn.Module):\n   def __init__(self, block, num_blocks, channels = [64, 128, 256, 512], num_classes=10):\n        super(ResNet4, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, channels[0], kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(channels[0])\n        self.layer1 = self._make_layer(block, channels[0], num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, channels[1], num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, channels[2], num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, channels[3], num_blocks[3], stride=2)\n        self.linear = nn.Linear(channels[3]*block.expansion, num_classes)\n\n   def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n                layers.append(block(self.in_planes, planes, stride))\n                self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n   def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\ndef ResNetCustom(blocks, channels):\n  layers = len(blocks)\n  if(layers==3):\n    return ResNet3(BasicBlock, blocks, channels)\n  else:\n    return ResNet4(BasicBlock, blocks, channels)","metadata":{"id":"BzWO6VSrCekp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to create total number of parameters\n\ndef getParameters(resnet):\n  total_params = 0\n  for x in filter(lambda p: p.requires_grad, resnet.parameters()):\n    total_params += np.prod(x.data.cpu().numpy().shape)\n  print(\"Total number of params\", total_params)","metadata":{"id":"GD2gQ6w2Cekp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating Model","metadata":{"id":"a2JYjt43Cekp"}},{"cell_type":"code","source":"# setting device as cuda\n\ndevice = 'cuda'","metadata":{"id":"SSPArmBqDFdp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to build the model\n\ndef build_model():\n    return ResNetCustom(blocks, channels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating our model 'net', and printing the number of parameters it has\n\nnet = build_model()\ngetParameters(net)\n\nif device == 'cuda':\n   net = torch.nn.DataParallel(net)\n   cudnn.benchmark = True\n","metadata":{"id":"_cvLEj3NCekr","outputId":"759736e6-0d3c-4ef9-8e08-6406ceb01fda","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# choosing the loss function\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"id":"ZCn7ph6FCeks","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading Dataset","metadata":{"id":"opIF00p7Darz"}},{"cell_type":"code","source":"class CIFAR10Dataset(Dataset):\n    def __init__(self, data, labels, transform=None):\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # The data is originally stored as a numpy array with shape (num_samples, 3, 32, 32)\n        # Transposing it to (num_samples, 32, 32, 3) for PIL\n        image = self.data[idx].transpose((1, 2, 0))\n        label = self.labels[idx]\n\n        # Converting the numpy array to a PIL Image\n        image = Image.fromarray(image.astype('uint8'))\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\ndef load_cifar10_batch(file):\n      with open(file, 'rb') as fo:\n          batch = pickle.load(fo, encoding='latin1')\n      data = batch['data']\n      labels = batch['labels']\n      data = data.reshape(-1, 3, 32, 32)\n      return data, labels\n\n# Function to load all CIFAR-10 data\ndef load_cifar10_data(data_dir):\n      train_data = []\n      train_labels = []\n      for i in range(1, 6):\n          batch_data, batch_labels = load_cifar10_batch(os.path.join(data_dir, f'data_batch_{i}'))\n          train_data.append(batch_data)\n          train_labels.extend(batch_labels)\n\n      train_data = np.vstack(train_data)\n      train_labels = np.array(train_labels)\n\n      test_data, test_labels = load_cifar10_batch(os.path.join(data_dir, 'test_batch'))\n      test_data = test_data.reshape(-1, 3, 32, 32)\n      test_labels = np.array(test_labels)\n\n      return train_data, train_labels, test_data, test_labels\n","metadata":{"id":"BeS6L5SLDi0k","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data paths\n\ndata_dir = ''\nif kaggle==1:\n  data_dir = '/kaggle/input/deep-learning-mini-project-spring-24-nyu/cifar-10-python/cifar-10-batches-py'\nelse:\n  data_dir = 'cifar-10-batches-py'","metadata":{"id":"FYxPC2kYCeks","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ORIGINAL TRANSFORM\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10), #newly added\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n","metadata":{"id":"a2mx8lrpCekt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CUTOUT, if we use cutout\n\nclass Cutout(object):\n    def __init__(self, n_holes, length):\n        self.n_holes = n_holes\n        self.length = length\n\n    def __call__(self, img):\n        h = img.size(1)\n        w = img.size(2)\n        mask = torch.ones(h, w, dtype=torch.float32)\n\n        for _ in range(self.n_holes):\n            y = torch.randint(0, h, (1,))\n            x = torch.randint(0, w, (1,))\n\n            y1 = int(torch.clamp(y - self.length / 2, 0, h).item())\n            x1 = int(torch.clamp(x - self.length / 2, 0, w).item())\n\n            y2 = int(torch.clamp(y + self.length / 2, 0, h).item())\n            x2 = int(torch.clamp(x + self.length / 2, 0, w).item())\n\n            mask[y1: y2, x1: x2] = 0\n\n        img = img * mask.unsqueeze(0)\n        return img\n\ntransform_train_cutout = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10), # newly added\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    Cutout(n_holes=1, length=8)  # Cutout added\n])","metadata":{"id":"yLSs1l74jc0m","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MIXUP, if we use mixup\n\ndef mixup_data(x, y, alpha=0.2, device='cuda'):\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(device)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    mixed_y = (y, y[index], lam)\n    return mixed_x, mixed_y\n","metadata":{"id":"gbwCdehykXzg","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CUTMIX, if we use cutmix\n\ndef cutmix_data(inputs, targets, alpha=1.0):\n    # Generate mixed sample\n    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n    batch_size = inputs.size(0)\n    index = torch.randperm(batch_size).to(inputs.device)\n\n    # Random rectangle region\n    H, W = inputs.size(2), inputs.size(3)\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = int(W * cut_rat)\n    cut_h = int(H * cut_rat)\n\n    # Uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n    inputs[:, :, bby1:bby2, bbx1:bbx2] = inputs[index, :, bby1:bby2, bbx1:bbx2]\n    # Adjusting lambda to exactly match the pixel ratio\n    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n    targets_a, targets_b = targets, targets[index]\n\n    return inputs, targets_a, targets_b, lam","metadata":{"id":"JPjDps3Bkmq7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create dataloaders","metadata":{"id":"uyedtmOnkYLd"}},{"cell_type":"code","source":"if load_dataset_online==0:\n  train_data, train_labels, test_data, test_labels = load_cifar10_data(data_dir)\n  train_dataset = CIFAR10Dataset(train_data, train_labels, transform=transform_train)\n  test_dataset = CIFAR10Dataset(test_data, test_labels, transform=transform_test)\n\n  train_dataset_cutout = CIFAR10Dataset(train_data, train_labels, transform=transform_train_cutout)\nelse:\n  train_dataset = torchvision.datasets.CIFAR10(root='/data', train=True, download=True, transform=transform_train)\n  test_dataset = torchvision.datasets.CIFAR10(root='/data', train=False, download=True, transform=transform_test)\n\n  train_dataset_cutout = torchvision.datasets.CIFAR10(root='/datacutout', train=True, download=True, transform=transform_train_cutout)\n","metadata":{"id":"cwVmAP6djunF","outputId":"542a587a-bc18-4733-b8ad-bd3084d33046","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create DataLoaders\ntrainloader = DataLoader(train_dataset, batch_size=our_batch_size, shuffle=True, num_workers=our_number_workers)\ntestloader = DataLoader(test_dataset, batch_size=our_batch_size, shuffle=False, num_workers=our_number_workers)\n\n# trainloader to be used when using cutout\ntrainloader_cutout = DataLoader(train_dataset_cutout, batch_size=our_batch_size, shuffle=True, num_workers=our_number_workers)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(trainloader))\nprint(len(trainloader_cutout))\nprint(len(testloader))","metadata":{"id":"5Yfjcn2BCekt","outputId":"7c61c0b7-e4bb-4a48-cc2b-df229b59c7d4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function if we are doing gradient clipping\n\ndef adaptive_gradient_clipping(parameters, clip_factor=0.01, eps=1e-3):\n    with torch.no_grad():\n        for p in parameters:\n            if p.grad is not None:\n                param_norm = torch.norm(p.data, p=2)\n                grad_norm = torch.norm(p.grad.data, p=2)\n                max_norm = param_norm * clip_factor\n                if grad_norm > max_norm + eps:\n                    clip_coef = max_norm / (grad_norm + eps)\n                    p.grad.data.mul_(clip_coef)","metadata":{"id":"-shVuMQxCeku","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining train function\n\ndef train(epoch, optimizer, mynet, mytrainloader, mixup = 0, cutmix = 0, clipping=0):\n    print('\\nEpoch: %d' % epoch)\n    epoch_start = perf_counter()  # Start timing the epoch\n    mynet.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    dataloading_time = 0\n    training_time = 0\n\n    train_accuracy = []\n    train_losses = []\n    \n    for batch_idx, (inputs, targets) in enumerate(mytrainloader):\n\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        if mixup==1:\n          inputs, mixed_targets = mixup_data(inputs, targets, alpha=0.5, device=device)\n          targets, shuffled_targets, lam = mixed_targets\n\n          optimizer.zero_grad()\n          outputs = mynet(inputs)\n\n          loss = lam * criterion(outputs, targets) + (1 - lam) * criterion(outputs, shuffled_targets)\n          loss.backward()\n          if (clipping==1):\n              adaptive_gradient_clipping(mynet.parameters(), clip_factor=0.01)\n          optimizer.step()\n\n          _, predicted = outputs.max(1)\n          correct += (predicted.eq(targets) | predicted.eq(shuffled_targets)).sum().item()\n          total += targets.size(0)\n          train_loss += loss.item()\n          epoch_accuracy = 100. * correct / total\n\n          train_accuracy.append(epoch_accuracy)\n          train_losses.append(loss.item())\n\n        elif cutmix==1:\n\n          targets_a, targets_b = targets.clone(), targets.clone()\n          if np.random.rand() < 0.5:\n            inputs, targets_a, targets_b, lam = cutmix_data(inputs, targets, alpha=1.0)\n            outputs = mynet(inputs)\n            loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n          else:\n            outputs = mynet(inputs)\n            loss = criterion(outputs, targets)\n\n          optimizer.zero_grad()\n          loss.backward()\n          if (clipping==1):\n              adaptive_gradient_clipping(mynet.parameters(), clip_factor=0.01)\n          optimizer.step()\n\n          _, predicted = outputs.max(1)\n          correct += (predicted.eq(targets_a) | predicted.eq(targets_b)).sum().item()\n          total += targets.size(0)\n          train_loss += loss.item()\n          epoch_accuracy = 100. * correct / total\n\n          train_accuracy.append(epoch_accuracy)\n          train_losses.append(loss.item())\n\n        else:\n\n          optimizer.zero_grad()\n          outputs = mynet(inputs)\n\n          loss = criterion(outputs, targets)\n          loss.backward()\n          if (clipping==1):\n              adaptive_gradient_clipping(mynet.parameters(), clip_factor=0.01)\n          optimizer.step()\n\n          train_loss += loss.item()\n          _, predicted = outputs.max(1)\n          total += targets.size(0)\n          correct += predicted.eq(targets).sum().item()\n          epoch_accuracy = 100. * correct / total\n\n          train_accuracy.append(epoch_accuracy)\n          train_losses.append(loss.item())\n\n\n    epoch_loss = train_loss / len(mytrainloader)\n\n    epoch_accuracy = 100. * correct / total\n    print(f'\\nEpoch: {epoch}, Loss: {epoch_loss:.3f}, Acc: {epoch_accuracy:.3f}%')\n\n    return epoch_accuracy, epoch_loss\n\n# defining test function\n\ndef test(optimizer, mynet):\n    mynet.eval()\n    test_loss = 0\n    correct = 0\n    total = 0\n\n    test_accuracy = []\n    test_losses = []\n\n    with torch.no_grad():\n        for batch_idx, (inputs, targets) in enumerate(testloader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = mynet(inputs)\n            loss = criterion(outputs, targets)\n\n            batch_loss = loss.item()\n            test_loss += batch_loss\n            _, predicted = outputs.max(1)\n            batch_sizee = targets.size(0)\n            total += batch_sizee\n            correct_batch =  predicted.eq(targets).sum().item()\n            correct += correct_batch\n\n            # Compute and store epoch-wise test accuracy\n            epoch_accuracy = 100. * correct / total\n            test_accuracy.append(epoch_accuracy)\n            test_losses.append(loss.item())\n\n            batch_accuracy = 100. * correct_batch / batch_sizee\n\n    epoch_loss = test_loss / len(testloader)\n    epoch_accuracy = 100. * correct / total\n    print(f'\\nTest Loss: {epoch_loss:.3f}, Acc: {epoch_accuracy:.3f}%')\n\n    return epoch_accuracy, epoch_loss\n\n","metadata":{"id":"lNqJRjCWCeku","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving Model\n\nif kaggle==1:\n  output_directory = '/kaggle/working/'\nelse:\n  output_directory = ''\n\n\ndef saveModel(mynet, number_of_epochs):\n    timestr = time.strftime(\"%m%d-%H%M\")\n    directory = os.path.join(output_directory, str(number_of_epochs))\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    torch.save({\n        'net': mynet,\n    }, os.path.join(directory, '{}_{}.tar'.format('Time', timestr)))","metadata":{"id":"CkvQ6kFACeku","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting function for train vs test graph\n\ndef plot_train_test_accuracy(train_acc, test_acc, train_loss, test_loss):\n    epochs = range(1, len(train_acc) + 1)\n    plt.figure(figsize=(12, 5))\n\n    # Plotting accuracy\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_acc, 'b', label='Training Accuracy')\n    plt.plot(epochs, test_acc, 'r', label='Test Accuracy')\n    plt.title('Training and Test Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Plotting loss\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_loss, 'b', label='Training Loss')\n    plt.plot(epochs, test_loss, 'r', label='Test Loss')\n    plt.title('Training and Test Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"id":"8UQPJT7JCeku","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to early stop\n\nclass EarlyStopper:\n    def __init__(self, patience=1, min_delta=0):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.max_validation_acc = float('inf')\n\n    def early_stop(self, validation_accuracy):\n        if validation_accuracy > self.max_validation_acc:\n            self.max_validation_acc = validation_accuracy\n            self.counter = 0\n        elif validation_accuracy < (self.max_validation_acc - self.min_delta):\n            self.counter += 1\n            if self.counter >= self.patience:\n                return True\n        return False","metadata":{"id":"vsnUOSRoCeku","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"WANDB","metadata":{"id":"QPKSirneCeku"}},{"cell_type":"code","source":"if use_wandb==1:\n  wandb.login(key = wandbapi)","metadata":{"id":"GQEUgM_NCekv","outputId":"0e17ec8c-8b2e-48e3-cdf3-ea6f6c62d11f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'random'\n    }\nmetric = {\n    'name': 'loss',\n    'goal': 'minimize'\n    }\nsweep_config['metric'] = metric\nparameters_dict = {\n    'optimizer': {\n        'values': ['adadelta', 'sgd', 'adadelta-clipping']\n        },\n    'learning_rate': {\n          'values': [0.1, 0.01, 0.001]\n        }    \n    'dataaug': {\n        'values': ['cutout', 'mixup', 'cutmix', 'cutout-mixup']\n        }\n    }\n\nsweep_config['parameters'] = parameters_dict\n","metadata":{"id":"x6kcDf4OCekv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pprint.pprint(sweep_config)","metadata":{"id":"A9TTBRV8Cekv","outputId":"55e4772e-2557-45bc-c827-10daf16bfe43","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_epoch = 0  # start from epoch 0 or last checkpoint epoch\ndef trainwandb(config=None):\n    wandb.init(config=config)\n    config = wandb.config\n\n    net = build_model()\n    getParameters(net)\n    if device == 'cuda':\n       net = torch.nn.DataParallel(net)\n       cudnn.benchmark = True\n\n    args_lr=0.001\n    \n    do_clipping = 0\n    if args_optimizer=='sgdn':\n      optimizer = optim.SGD(net.parameters(), lr=args_lr, momentum=0.9, weight_decay=args_weight_decay, nesterov=True)\n    elif args_optimizer=='adadelta':\n      optimizer = optim.Adadelta(net.parameters(), lr=args_lr, weight_decay=args_weight_decay)\n    elif args_optimizer=='adadelta-clipping':\n      optimizer = optim.Adadelta(net.parameters(), lr=args_lr, weight_decay=args_weight_decay)\n      do_clipping = 1\n    else: #sgd\n      optimizer = optim.SGD(net.parameters(), lr=args_lr, momentum=0.9, weight_decay=args_weight_decay)\n\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=t_max)\n\n    train_accuracies = []\n    test_accuracies = []\n    train_losses = []\n    test_losses = []\n\n    if earlystop:\n      early_stopper = EarlyStopper(patience=5, min_delta=2)\n\n    for epoch in range(start_epoch, start_epoch+number_of_epochs):\n        if config.dataaug=='cutout': #'cutout', 'mixup', 'cutmix', 'cutout-mixup' #trainloader, trainloader_cutout\n          train_acc, train_loss = train(epoch, optimizer, net, trainloader_cutout, 0, 0, do_clipping)\n        elif config.dataaug=='mixup':\n          train_acc, train_loss = train(epoch, optimizer, net, trainloader, 1, 0, do_clipping)\n        elif config.dataaug=='cutmix':\n          train_acc, train_loss = train(epoch, optimizer, net, trainloader, 0, 1, do_clipping)\n        else: #cutout-mixup\n          train_acc, train_loss = train(epoch, optimizer, net, trainloader_cutout, 1, 0, do_clipping)\n\n        test_acc, test_loss = test(optimizer, net)\n\n        wandb.log({\"epoch\": epoch, \"train_accuracy\": train_acc, \"train_loss\": train_loss,\n                   \"test_accuracy\": test_acc, \"test_loss\": test_loss})\n\n        scheduler.step()\n        \n        if epoch+start_epoch==80:\n            args_lr/=10\n        if epoch+start_epoch==150:\n            args_lr/=10\n        for param_group in optimizer.param_groups:\n            param_group['lr']=args_lr\n        \n        train_accuracies.append(train_acc)\n        test_accuracies.append(test_acc)\n        train_losses.append(train_loss)\n        test_losses.append(test_loss)\n\n        if(epoch%save_freq==0):\n            saveModel(net, epoch)\n        if earlystop:\n          if early_stopper.early_stop(test_acc) and test_acc>earlystop_threshold:\n            wandb.log({\"early_stop\": epoch})\n            break\n\n    saveModel(net, number_of_epochs)\n\n    # Plot train vs test accuracy graph\n    plot_train_test_accuracy(train_accuracies, test_accuracies, train_losses, test_losses)\n\n    test(optimizer, net)\n    wandb.log({\"final_test_loss\": test_losses[-1]})\n    wandb.finish()","metadata":{"id":"utgKnD1eCekv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_wandb==1:\n  sweep_id = wandb.sweep(sweep_config, project=\"DL-mini-project\")","metadata":{"id":"TqgeP9C8Cekv","outputId":"ba7fccbc-9209-4349-a026-7e08b85001c7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_wandb==1:\n  wandb.agent(sweep_id, trainwandb, count=1)","metadata":{"id":"CCCoSuLJCekv","outputId":"42da633f-fd03-4f90-8c35-09e4829a1c4a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"If running without WANDB","metadata":{"id":"hOd-vV77tm1O"}},{"cell_type":"markdown","source":"Loading pkl model if needed:","metadata":{"id":"Jq2DbaiTw_r9"}},{"cell_type":"code","source":"if load_model == 1:\n  loadFilename = load_model_name\n  checkpoint = torch.load(loadFilename)\n  net = checkpoint['net']","metadata":{"id":"gNMjWV-sw9dG","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if use_wandb==0:\n  do_clipping = 0\n  if args_optimizer=='sgdn':\n    optimizer = optim.SGD(net.parameters(), lr=args_lr, momentum=0.9, weight_decay=args_weight_decay, nesterov=True)\n  elif args_optimizer=='adadelta':\n    optimizer = optim.Adadelta(net.parameters(), lr=args_lr, weight_decay=args_weight_decay)\n  elif args_optimizer=='adadelta-clipping':\n    optimizer = optim.Adadelta(net.parameters(), lr=args_lr, weight_decay=args_weight_decay)\n    do_clipping = 1\n  else: #sgd\n    optimizer = optim.SGD(net.parameters(), lr=args_lr, momentum=0.9, weight_decay=args_weight_decay)\n\n  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=t_max)\n  scheduler.step()\n\n  train_accuracies = []\n  test_accuracies = []\n  train_losses = []\n  test_losses = []\n\n  if earlystop:\n    early_stopper = EarlyStopper(patience=earlystop_patience, min_delta=earlystop_mindelta)\n    \n  for epoch in range(start_epoch, start_epoch+number_of_epochs):\n      train_acc, train_loss = train(epoch, optimizer, net, do_clipping)\n      test_acc, test_loss = test(optimizer, net)\n\n      train_accuracies.append(train_acc)\n      test_accuracies.append(test_acc)\n      train_losses.append(train_loss)\n      test_losses.append(test_loss)\n\n      if(epoch%save_freq==0):\n          saveModel(net, epoch)\n      if earlystop==1:\n        if early_stopper.early_stop(test_acc) and test_acc>earlystop_threshold:\n          wandb.log({\"early_stop\": epoch})\n          break\n\n  saveModel(net, number_of_epochs)\n\n  # Plot train vs test accuracy graph\n  plot_train_test_accuracy(train_accuracies, test_accuracies, train_losses, test_losses)\n\n  test(optimizer, net)","metadata":{"id":"bSZaWr8wtpAd","trusted":true},"execution_count":null,"outputs":[]}]}